{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60 60 60 59\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_titles</th>\n",
       "      <th>all_companies</th>\n",
       "      <th>all_locations</th>\n",
       "      <th>all_times</th>\n",
       "      <th>all_links</th>\n",
       "      <th>job_post_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineer (L5)</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>United States</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3755880784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Engineer</td>\n",
       "      <td>Team Remotely Inc</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-data...</td>\n",
       "      <td>3930753618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Junior Data Engineer</td>\n",
       "      <td>Patterned Learning Career</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-data...</td>\n",
       "      <td>3930750823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineer (Data as a Service)</td>\n",
       "      <td>Xplor Technologies</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3929441554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Worth AI</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3929025838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Engineer (Remote)</td>\n",
       "      <td>KnowBe4</td>\n",
       "      <td>Clearwater, FL</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3923194037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>CAI</td>\n",
       "      <td>United States</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3902941891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Venafi</td>\n",
       "      <td>United States</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3881264213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Loopio</td>\n",
       "      <td>Hub, CA</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3927225420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Morgan King Technology</td>\n",
       "      <td>New York, United States</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3930770195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Analytics Engineer II (REMOTE)</td>\n",
       "      <td>DICK'S Sporting Goods</td>\n",
       "      <td>United States</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/analytics-e...</td>\n",
       "      <td>3922468966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Genesis10</td>\n",
       "      <td>Eagan, MN</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3921602198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Calm</td>\n",
       "      <td>United States</td>\n",
       "      <td>12 hours ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3910382948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Junior Data Engineer</td>\n",
       "      <td>HireMeFast LLC</td>\n",
       "      <td>Little Rock, AR</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-data...</td>\n",
       "      <td>3930754430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Addison Group</td>\n",
       "      <td>United States</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3921696726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Senior Data Engineer (PST Time zone)</td>\n",
       "      <td>iTalent Digital</td>\n",
       "      <td>United States</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3926994302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Rebelstork</td>\n",
       "      <td>United States</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3922048153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>AddSource</td>\n",
       "      <td>United States</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3929020106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Engineer - Data</td>\n",
       "      <td>The Wendy's Company</td>\n",
       "      <td>Dublin, OH</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/engineer-da...</td>\n",
       "      <td>3927119088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Workiy Inc.</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3927975627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sr. Data Engineer II</td>\n",
       "      <td>Oak Street Health</td>\n",
       "      <td>United States</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-data-eng...</td>\n",
       "      <td>3925187902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Junior Data Engineer</td>\n",
       "      <td>Phoenix Recruitment</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>3 hours ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/junior-data...</td>\n",
       "      <td>3930750875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Revel IT</td>\n",
       "      <td>Columbus, OH</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3927989251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Global Soft Systems, Inc.</td>\n",
       "      <td>United States</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3928081205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Engineer 3 (REMOTE)</td>\n",
       "      <td>DivIHN Integration Inc</td>\n",
       "      <td>United States</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3929087956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Calyptus</td>\n",
       "      <td>California, United States</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3930094709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Calyptus</td>\n",
       "      <td>New York, United States</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3930093732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Senior Data Engineer - Tampa, FL</td>\n",
       "      <td>PrismHR</td>\n",
       "      <td>Tampa, FL</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3925837888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Senior Data Engineer - Duluth, GA</td>\n",
       "      <td>PrismHR</td>\n",
       "      <td>United States</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3925680218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Senior Data Engineer - Tampa, FL</td>\n",
       "      <td>PrismHR</td>\n",
       "      <td>United States</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3925681202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Senior Data Engineer - Duluth, GA</td>\n",
       "      <td>PrismHR</td>\n",
       "      <td>Duluth, GA</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3925837894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Data Reporting Engineer</td>\n",
       "      <td>VideoAmp</td>\n",
       "      <td>United States</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-report...</td>\n",
       "      <td>3926337414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Senior Data Engineer- Chandler, AZ</td>\n",
       "      <td>PrismHR</td>\n",
       "      <td>Chandler, AZ</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3925841108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Data Engineer - Remote</td>\n",
       "      <td>AdTheorent</td>\n",
       "      <td>Jacksonville, FL</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3929404240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Indsafri</td>\n",
       "      <td>United States</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3926361411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Fixity Technologies</td>\n",
       "      <td>United States</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3926341926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>Jersey City, NJ</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3928082239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Software Engineer (L5) - Ads Platform Engineering</td>\n",
       "      <td>Netflix</td>\n",
       "      <td>United States</td>\n",
       "      <td>2 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/software-en...</td>\n",
       "      <td>3669206397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Insight Global</td>\n",
       "      <td>Louisville Metropolitan Area</td>\n",
       "      <td>2 hours ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3925056503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Rearc</td>\n",
       "      <td>United States</td>\n",
       "      <td>9 hours ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3930123619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Marketing Data Engineer</td>\n",
       "      <td>Absorb Software</td>\n",
       "      <td>United States</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/marketing-d...</td>\n",
       "      <td>3885799229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Klimbnow</td>\n",
       "      <td>United States</td>\n",
       "      <td>1 hour ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3925052290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Arrow Search Partners</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3927903115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>PRI Technology</td>\n",
       "      <td>United States</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3926909108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bentley Systems</td>\n",
       "      <td>Exton, PA</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3926368345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Cloudera Data Engineer</td>\n",
       "      <td>GAP Solutions, Inc.</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/cloudera-da...</td>\n",
       "      <td>3925267733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Data Engineer (mid-level)</td>\n",
       "      <td>KamisPro</td>\n",
       "      <td>Northeastern United States</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3925272422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Sr. Data Engineer</td>\n",
       "      <td>Gravity IT Resources</td>\n",
       "      <td>United States</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-data-eng...</td>\n",
       "      <td>3926179607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Senior Data Engineer- Chandler, AZ</td>\n",
       "      <td>PrismHR</td>\n",
       "      <td>United States</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3925675818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Visionaire Partners</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3926281423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>STAND 8 Technology Services</td>\n",
       "      <td>Los Angeles Metropolitan Area</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3920252466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Senior Data Platform Engineer</td>\n",
       "      <td>BLACKCLOAK</td>\n",
       "      <td>Orlando, FL</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/senior-data...</td>\n",
       "      <td>3921153993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ETL Pentaho Data Engineer</td>\n",
       "      <td>Adame Services LLC</td>\n",
       "      <td>United States</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/etl-pentaho...</td>\n",
       "      <td>3924412512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Data Engineer II</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3927281300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>utlikers Inc</td>\n",
       "      <td>United States</td>\n",
       "      <td>1 day ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/sr-data-eng...</td>\n",
       "      <td>3926575138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Sr Data Engineer</td>\n",
       "      <td>ROR</td>\n",
       "      <td>United States</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/remote-work...</td>\n",
       "      <td>3929064524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Remote Work - Need Data Engineer</td>\n",
       "      <td>Steneral Consulting</td>\n",
       "      <td>United States</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3927536964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Data Engineer (Fivetran &amp; Airflow)</td>\n",
       "      <td>AGILIOUS</td>\n",
       "      <td>Bethesda, MD</td>\n",
       "      <td>4 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/big-data-en...</td>\n",
       "      <td>3925738145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>Sciata</td>\n",
       "      <td>Scottsdale, AZ</td>\n",
       "      <td>5 days ago</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/data-engine...</td>\n",
       "      <td>3929271072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           all_titles  \\\n",
       "0                                  Data Engineer (L5)   \n",
       "1                                Junior Data Engineer   \n",
       "2                                Junior Data Engineer   \n",
       "3                   Data Engineer (Data as a Service)   \n",
       "4                                       Data Engineer   \n",
       "5                              Data Engineer (Remote)   \n",
       "6                                       Data Engineer   \n",
       "7                                       Data Engineer   \n",
       "8                                       Data Engineer   \n",
       "9                                       Data Engineer   \n",
       "10                     Analytics Engineer II (REMOTE)   \n",
       "11                                      Data Engineer   \n",
       "12                               Senior Data Engineer   \n",
       "13                               Junior Data Engineer   \n",
       "14                                      Data Engineer   \n",
       "15               Senior Data Engineer (PST Time zone)   \n",
       "16                                      Data Engineer   \n",
       "17                                      Data Engineer   \n",
       "18                                    Engineer - Data   \n",
       "19                                      Data Engineer   \n",
       "20                               Sr. Data Engineer II   \n",
       "21                               Junior Data Engineer   \n",
       "22                                      Data Engineer   \n",
       "23                                      Data Engineer   \n",
       "24                           Data Engineer 3 (REMOTE)   \n",
       "25                               Senior Data Engineer   \n",
       "26                               Senior Data Engineer   \n",
       "27                   Senior Data Engineer - Tampa, FL   \n",
       "28                  Senior Data Engineer - Duluth, GA   \n",
       "29                   Senior Data Engineer - Tampa, FL   \n",
       "30                  Senior Data Engineer - Duluth, GA   \n",
       "31                            Data Reporting Engineer   \n",
       "32                 Senior Data Engineer- Chandler, AZ   \n",
       "33                             Data Engineer - Remote   \n",
       "34                                      Data Engineer   \n",
       "35                                      Data Engineer   \n",
       "36                               Senior Data Engineer   \n",
       "37  Software Engineer (L5) - Ads Platform Engineering   \n",
       "38                                      Data Engineer   \n",
       "39                               Senior Data Engineer   \n",
       "40                            Marketing Data Engineer   \n",
       "41                               Senior Data Engineer   \n",
       "42                                      Data Engineer   \n",
       "43                               Senior Data Engineer   \n",
       "44                                      Data Engineer   \n",
       "45                             Cloudera Data Engineer   \n",
       "46                          Data Engineer (mid-level)   \n",
       "47                                  Sr. Data Engineer   \n",
       "48                 Senior Data Engineer- Chandler, AZ   \n",
       "49                                      Data Engineer   \n",
       "50                                      Data Engineer   \n",
       "51                      Senior Data Platform Engineer   \n",
       "52                          ETL Pentaho Data Engineer   \n",
       "53                                   Data Engineer II   \n",
       "54                                      Data Engineer   \n",
       "55                                   Sr Data Engineer   \n",
       "56                   Remote Work - Need Data Engineer   \n",
       "57                 Data Engineer (Fivetran & Airflow)   \n",
       "58                                  Big Data Engineer   \n",
       "\n",
       "                  all_companies                  all_locations     all_times  \\\n",
       "0                       Netflix                  United States     1 day ago   \n",
       "1             Team Remotely Inc                    Chicago, IL   3 hours ago   \n",
       "2     Patterned Learning Career                     Denver, CO   3 hours ago   \n",
       "3            Xplor Technologies                    Atlanta, GA    2 days ago   \n",
       "4                      Worth AI                    Orlando, FL    3 days ago   \n",
       "5                       KnowBe4                 Clearwater, FL    3 days ago   \n",
       "6                           CAI                  United States    6 days ago   \n",
       "7                        Venafi                  United States     1 day ago   \n",
       "8                        Loopio                        Hub, CA    4 days ago   \n",
       "9        Morgan King Technology        New York, United States   2 hours ago   \n",
       "10        DICK'S Sporting Goods                  United States    3 days ago   \n",
       "11                    Genesis10                      Eagan, MN    6 days ago   \n",
       "12                         Calm                  United States  12 hours ago   \n",
       "13               HireMeFast LLC                Little Rock, AR   3 hours ago   \n",
       "14                Addison Group                  United States    5 days ago   \n",
       "15              iTalent Digital                  United States    4 days ago   \n",
       "16                   Rebelstork                  United States    5 days ago   \n",
       "17                    AddSource                  United States    3 days ago   \n",
       "18          The Wendy's Company                     Dublin, OH    4 days ago   \n",
       "19                  Workiy Inc.                     Austin, TX    4 days ago   \n",
       "20            Oak Street Health                  United States    6 days ago   \n",
       "21          Phoenix Recruitment                   New York, NY   3 hours ago   \n",
       "22                     Revel IT                   Columbus, OH    4 days ago   \n",
       "23    Global Soft Systems, Inc.                  United States    3 days ago   \n",
       "24       DivIHN Integration Inc                  United States    2 days ago   \n",
       "25                     Calyptus      California, United States     1 day ago   \n",
       "26                     Calyptus        New York, United States     1 day ago   \n",
       "27                      PrismHR                      Tampa, FL    5 days ago   \n",
       "28                      PrismHR                  United States    6 days ago   \n",
       "29                      PrismHR                  United States    6 days ago   \n",
       "30                      PrismHR                     Duluth, GA    5 days ago   \n",
       "31                     VideoAmp                  United States    5 days ago   \n",
       "32                      PrismHR                   Chandler, AZ    5 days ago   \n",
       "33                   AdTheorent               Jacksonville, FL    2 days ago   \n",
       "34                     Indsafri                  United States    5 days ago   \n",
       "35          Fixity Technologies                  United States    5 days ago   \n",
       "36              Tiger Analytics                Jersey City, NJ    3 days ago   \n",
       "37                      Netflix                  United States    2 days ago   \n",
       "38               Insight Global   Louisville Metropolitan Area   2 hours ago   \n",
       "39                        Rearc                  United States   9 hours ago   \n",
       "40              Absorb Software                  United States    4 days ago   \n",
       "41                     Klimbnow                  United States    1 hour ago   \n",
       "42        Arrow Search Partners                   New York, NY    4 days ago   \n",
       "43               PRI Technology                  United States    5 days ago   \n",
       "44              Bentley Systems                      Exton, PA    4 days ago   \n",
       "45          GAP Solutions, Inc.                    Atlanta, GA    5 days ago   \n",
       "46                     KamisPro     Northeastern United States    5 days ago   \n",
       "47         Gravity IT Resources                  United States    5 days ago   \n",
       "48                      PrismHR                  United States    6 days ago   \n",
       "49          Visionaire Partners                    Atlanta, GA    5 days ago   \n",
       "50  STAND 8 Technology Services  Los Angeles Metropolitan Area    4 days ago   \n",
       "51                   BLACKCLOAK                    Orlando, FL    6 days ago   \n",
       "52           Adame Services LLC                  United States    6 days ago   \n",
       "53                    Microsoft                    Atlanta, GA    4 days ago   \n",
       "54                 utlikers Inc                  United States     1 day ago   \n",
       "55                          ROR                  United States    5 days ago   \n",
       "56          Steneral Consulting                  United States    3 days ago   \n",
       "57                     AGILIOUS                   Bethesda, MD    4 days ago   \n",
       "58                       Sciata                 Scottsdale, AZ    5 days ago   \n",
       "\n",
       "                                            all_links job_post_number  \n",
       "0   https://www.linkedin.com/jobs/view/data-engine...      3755880784  \n",
       "1   https://www.linkedin.com/jobs/view/junior-data...      3930753618  \n",
       "2   https://www.linkedin.com/jobs/view/junior-data...      3930750823  \n",
       "3   https://www.linkedin.com/jobs/view/data-engine...      3929441554  \n",
       "4   https://www.linkedin.com/jobs/view/data-engine...      3929025838  \n",
       "5   https://www.linkedin.com/jobs/view/data-engine...      3923194037  \n",
       "6   https://www.linkedin.com/jobs/view/data-engine...      3902941891  \n",
       "7   https://www.linkedin.com/jobs/view/data-engine...      3881264213  \n",
       "8   https://www.linkedin.com/jobs/view/data-engine...      3927225420  \n",
       "9   https://www.linkedin.com/jobs/view/data-engine...      3930770195  \n",
       "10  https://www.linkedin.com/jobs/view/analytics-e...      3922468966  \n",
       "11  https://www.linkedin.com/jobs/view/data-engine...      3921602198  \n",
       "12  https://www.linkedin.com/jobs/view/senior-data...      3910382948  \n",
       "13  https://www.linkedin.com/jobs/view/junior-data...      3930754430  \n",
       "14  https://www.linkedin.com/jobs/view/data-engine...      3921696726  \n",
       "15  https://www.linkedin.com/jobs/view/senior-data...      3926994302  \n",
       "16  https://www.linkedin.com/jobs/view/data-engine...      3922048153  \n",
       "17  https://www.linkedin.com/jobs/view/data-engine...      3929020106  \n",
       "18  https://www.linkedin.com/jobs/view/engineer-da...      3927119088  \n",
       "19  https://www.linkedin.com/jobs/view/data-engine...      3927975627  \n",
       "20  https://www.linkedin.com/jobs/view/sr-data-eng...      3925187902  \n",
       "21  https://www.linkedin.com/jobs/view/junior-data...      3930750875  \n",
       "22  https://www.linkedin.com/jobs/view/data-engine...      3927989251  \n",
       "23  https://www.linkedin.com/jobs/view/data-engine...      3928081205  \n",
       "24  https://www.linkedin.com/jobs/view/data-engine...      3929087956  \n",
       "25  https://www.linkedin.com/jobs/view/senior-data...      3930094709  \n",
       "26  https://www.linkedin.com/jobs/view/senior-data...      3930093732  \n",
       "27  https://www.linkedin.com/jobs/view/senior-data...      3925837888  \n",
       "28  https://www.linkedin.com/jobs/view/senior-data...      3925680218  \n",
       "29  https://www.linkedin.com/jobs/view/senior-data...      3925681202  \n",
       "30  https://www.linkedin.com/jobs/view/senior-data...      3925837894  \n",
       "31  https://www.linkedin.com/jobs/view/data-report...      3926337414  \n",
       "32  https://www.linkedin.com/jobs/view/senior-data...      3925841108  \n",
       "33  https://www.linkedin.com/jobs/view/data-engine...      3929404240  \n",
       "34  https://www.linkedin.com/jobs/view/data-engine...      3926361411  \n",
       "35  https://www.linkedin.com/jobs/view/data-engine...      3926341926  \n",
       "36  https://www.linkedin.com/jobs/view/senior-data...      3928082239  \n",
       "37  https://www.linkedin.com/jobs/view/software-en...      3669206397  \n",
       "38  https://www.linkedin.com/jobs/view/data-engine...      3925056503  \n",
       "39  https://www.linkedin.com/jobs/view/senior-data...      3930123619  \n",
       "40  https://www.linkedin.com/jobs/view/marketing-d...      3885799229  \n",
       "41  https://www.linkedin.com/jobs/view/senior-data...      3925052290  \n",
       "42  https://www.linkedin.com/jobs/view/data-engine...      3927903115  \n",
       "43  https://www.linkedin.com/jobs/view/senior-data...      3926909108  \n",
       "44  https://www.linkedin.com/jobs/view/data-engine...      3926368345  \n",
       "45  https://www.linkedin.com/jobs/view/cloudera-da...      3925267733  \n",
       "46  https://www.linkedin.com/jobs/view/data-engine...      3925272422  \n",
       "47  https://www.linkedin.com/jobs/view/sr-data-eng...      3926179607  \n",
       "48  https://www.linkedin.com/jobs/view/senior-data...      3925675818  \n",
       "49  https://www.linkedin.com/jobs/view/data-engine...      3926281423  \n",
       "50  https://www.linkedin.com/jobs/view/data-engine...      3920252466  \n",
       "51  https://www.linkedin.com/jobs/view/senior-data...      3921153993  \n",
       "52  https://www.linkedin.com/jobs/view/etl-pentaho...      3924412512  \n",
       "53  https://www.linkedin.com/jobs/view/data-engine...      3927281300  \n",
       "54  https://www.linkedin.com/jobs/view/sr-data-eng...      3926575138  \n",
       "55  https://www.linkedin.com/jobs/view/remote-work...      3929064524  \n",
       "56  https://www.linkedin.com/jobs/view/data-engine...      3927536964  \n",
       "57  https://www.linkedin.com/jobs/view/big-data-en...      3925738145  \n",
       "58  https://www.linkedin.com/jobs/view/data-engine...      3929271072  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from requests_html import HTMLSession\n",
    "from selectolax.parser import HTMLParser\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = f\"https://www.linkedin.com/jobs/search?keywords=Data%2BEngineer&location=United%2BStates&geoId=103644278&f_TPR=r604800&f_WT=2&currentJobId=3714054589&position=1&pageNum=0\"\n",
    "\n",
    "session = HTMLSession()\n",
    "r = session.get(url)\n",
    "node = HTMLParser(r.text)\n",
    "\n",
    "titles = node.css(\".job-search-card div h3\")\n",
    "companies = node.css(\".job-search-card div h4\")\n",
    "locations = node.css(\".job-search-card__location\")\n",
    "times = node.css(\".base-search-card__metadata time\")\n",
    "links = node.css(\".job-search-card a\")\n",
    "\n",
    "all_titles   = [(title.text()).strip() for title in titles]\n",
    "all_companies   = [(company.text()).strip() for company in companies]\n",
    "all_locations  = [(location.text()).strip()  for location in locations]\n",
    "all_times  = [time.text().strip() for time in times]\n",
    "all_links  = [link.attributes[\"href\"] for link in links][::2]\n",
    "job_post_number = [(lstr.split(\"?\"))[0][-10:] for lstr in all_links]\n",
    "\n",
    "print(len(titles),len(all_companies),len(all_locations),len(all_times),len(all_links))\n",
    "\n",
    "list_of_tuples = list(zip(all_titles,\n",
    "                          all_companies,\n",
    "                          all_locations,\n",
    "                          all_times,\n",
    "                          all_links,\n",
    "                          job_post_number))\n",
    "\n",
    "df = pd.DataFrame(list_of_tuples, columns = ['all_titles', 'all_companies', \"all_locations\", \"all_times\", \"all_links\", \"job_post_number\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Netflix  our mission is to entertain the world. With 200+ million paid members in over 190 countries on millions of devices; enjoying TV series  documentaries  and feature films across a wide variety of genres and languages - Netflix is reinventing entertainment from end to end. We are revolutionizing how shows and movies are produced  pushing technological boundaries to efficiently deliver streaming video at a massive scale over the internet  and continuously improving the end-to-end user experience with Netflix across their member journey.We pride ourselves on using data to inform our decision-making as we work towards our mission. This requires curating data across various domains such as Growth  Finance  Product  Content  and Studio. All of this data collection and curation is made possible thanks to the amazing Data Engineers of Netflix who bring this data to life.Data Engineering at Netflix is a role that requires building systems to process data efficiently and modeling the data to power analytics. These solutions can range from batch data pipelines that bring to life business metrics to real-time processing services that integrate with our core product features. In addition  we require our Data Engineers to have a rich understanding of large distributed systems on which our data solutions rely. Candidates should have knowledge across several of these skill sets and usually need to be deep in at least one. As a Data Engineer  you also need to have strong communication skills since you will need to collaborate with business  engineering  and data science teams to enable a culture of learning. Learn more about the work of data engineers at Netflix.Location of work: We are considering candidates who are willing to relocate to Los Gatos  California  as well as fully-remote candidates (remote in the US with occasional visits to Los Gatos) depending on the team your skills are most aligned with.Who are you?You strive to write elegant code  and you're comfortable with picking up new technologies independentlyYou are proficient in at least one major programming language (e.g. Java  Scala  Python) and comfortable working with SQLYou enjoy helping teams push the boundaries of analytical insights  creating new product features using data  and powering machine learning modelsYou have a strong background in at least one of the following: distributed data processing or software engineering of data services  or data modelingYou are familiar with big data technologies like Spark or Flink and comfortable working with web-scale datasetsYou have an eye for detail  good data intuition  and a passion for data qualityYou appreciate the importance of great documentation and data debugging skillsYou relate to and embody many of the aspects of the Netflix Culture. You love working independently while also collaborating and giving/receiving candid feedbackYou are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risksOur compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation  we rely on market indicators and consider your specific job family  background  skills  and experience to determine your compensation in the market range. The range for is $170 000 - $720 000.Netflix provides comprehensive benefits including Health Plans  Mental Health support  a 401(k) Retirement Plan with employer match  Stock Option Program  Disability Programs  Health Savings and Flexible Spending Accounts  Family-forming benefits  and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation  holidays  and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.Netflix is a unique culture and environment. Learn more here.We are an equal-opportunity employer and celebrate diversity  recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race  religion  color  ancestry  national origin  caste  sex  sexual orientation  gender  gender identity or expression  age  disability  medical condition  pregnancy  genetic makeup  marital status  or military service.,Not Applicable,Full-time\n",
      "\n",
      "This is a remote position. Junior Data Engineer (1 year experience  remote)Be part of our future! This job posting builds our talent pool for potential future openings. We'll compare your skills and experience against both current and future needs. If there's a match  we'll contact you directly. No guarantee of immediate placement  and we only consider applications from US/Canada residents during the application process. Hiring Type: Full-Time Base Salary: $57K-$67K Per Annum.Position SummaryJoin the fast-paced  innovative  and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect  predict  and recommend solutions to correct issues before system impact and enhance the efficiency  reliability  and performance of CVS Health’s IT operations.Key Responsibilities include:Data pipeline development: Designed  implemented  and managed data pipelines for extracting  transforming  and loading data from various sources into data lakes for processing  analytics  and correlation. Data modeling: Create and maintain data models ensuring data quality  scalability  and efficiency Develop and automate processes to clean  transform  and prepare data for analytics  ensuring data accuracy and consistency Data Integration: Integrate data from disparate sources  both structured and unstructured to provide a unified view of key infrastructure platform and application data Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation Create/maintain documentation for data processes  data flows  and system configurations Performance Optimization- Monitor and optimize data pipelines and systems for performance  scalability and cost-effectiveness Characteristics of this role:Team Player: Willing to teach  share knowledge  and work with others to make the team successful. Communication: Exceptional verbal  written  organizational  presentation  and communication skills. Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. Attention to detail: Systematically and accurately research future solutions and current problems. Strong work ethic: The innate drive to do work extremely well. Passion: A drive to deliver better products and services than expected to customers. Required Qualifications2+ years of programming experience in languages such as Python  Java  SQL 2+ years of experience with ETL tools and database management (relational  non-relational) 2+ years of experience in data modeling techniques and tools to design efficient scalable data structures Skills in data quality assessment  data cleansing  and data validation Preferred QualificationsKnowledge of big data technologies and cloud platforms Experience with technologies like PySpark  Databricks  and Azure Synapse. EducationBachelor’s degree in Computer Science  Information Technology  or related field  or equivalent working experience,Mid-Senior level,Full-time\n",
      "\n",
      "This is a remote position.Junior Data Engineer - Remote Job  1+ Year ExperienceAnnual Income: $57K - $77KA valid work permit is necessary in the USAbout us: Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding  real-time multiplayer editing  and the ability to build  test  and deploy directly from the browser. The platform also provides tightly integrated code generation  editing  and output capabilities.Are you a passionate and detail-oriented individual with a knack for problem-solving? Do you thrive in a fast-paced  collaborative environment? If so  then this Junior Data Engineer role at CVS Health could be your perfect match!In this exciting role  you'll play a key role in building and scaling our cutting-edge AIOps platform. You'll work alongside a talented team to develop machine learning and AI solutions that will revolutionize CVS Health's IT operations.Here's what you'll do:Design  implement  and manage data pipelines to extract  transform  and load data for analysis and insights. Develop and automate data cleaning  transformation  and preparation processes to ensure data quality and consistency. Integrate data from various sources to create a unified view of our IT infrastructure and applications. Leverage big data technologies like Kafka to handle large data volumes efficiently. Implement data security measures to safeguard sensitive information. Create and maintain documentation for data processes  data flows  and system configurations. Continuously monitor and optimize data pipelines and systems for performance  scalability  and cost-effectiveness. To be successful  you'll need:2+ years of programming experience in Python  Java  and SQL. 2+ years of experience with ETL tools and database management (relational and non-relational). 2+ years of experience with data modeling techniques and tools for designing efficient data structures. Strong skills in data quality assessment  cleansing  and validation. Excellent communication  collaboration  and problem-solving skills. A meticulous attention to detail and a strong work ethic. Bonus points if you have:Knowledge of big data technologies and cloud platforms (e.g.  Azure Synapse). Experience with PySpark and Data-bricks. We offer:The opportunity to work on a cutting-edge AIOps platform that's transforming healthcare. A collaborative and supportive work environment where you can learn and grow. A chance to make a real impact on the success of CVS Health. Please note: While this role is fast-paced  we value work-life balance and offer a comprehensive benefits package.Why Patterned Learning LLC?Patterned Learning can provide intelligent suggestions  automate repetitive tasks  and assist developers in writing code more effectively. This can help reduce coding errors  improve productivity  and accelerate the development process.Pattern recognition is particularly relevant in the context of coding. Neural networks  intense learning models  are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data  making them well-suited for tasks like code analysis and generation.,Mid-Senior level,Full-time\n",
      "\n",
      "Company DescriptionAt Xplor we help businesses succeed by giving them the software  payments  and commerce-accelerating technologies they need to thrive.We know our clients and partners because we once were our clients. We understand their industry  customers  and unique goals so that we can help them overcome obstacles and leave a lasting legacy.Job DescriptionWrite and optimize SQL queries for data retrieval  manipulation  and analysis.Develop stored procedures  functions  and triggers for efficient data processing and management.Utilize advanced SQL techniques to perform data transformations and aggregations.Manage and maintain relational databases including SQL Server  MySQL  PostgreSQL  and Snowflake.Design and implement database schemas  tables  indexes  and views to support application requirements.Design  develop  and implement ETL (Extract  Transform  Load) processes to integrate data from various sources into data warehouses or data lakes.Ensure the reliability  scalability  and efficiency of ETL pipelines for large-scale data processing.Identify and resolve data quality issues through data profiling  cleansing  and normalization techniques.Design and maintain dimensional data models for data warehouses to support reporting and analytics requirements.Work closely with data architects and analysts to understand data requirements and translate them into effective data models.QualificationsBachelor's degree in Computer Science  Information Technology  or a related field.Hands-on experience with SQL Server  MySQL  PostgreSQL  and Snowflake.Proficiency in writing complex SQL queries and optimizing database performance.Strong understanding of data warehousing concepts and dimensional modeling techniques.Excellent problem-solving skills and attention to detail.Effective communication and collaboration skills in a team environment.Additional InformationLife at XplorYou’ll be part of a global network of talented colleagues who support your success. We look for commonalities and shared passions and give people the tools they need to deliver great work and grow at speed.Some Of The Perks Of Working With Us12 weeks Gender Neutral Paid Parental Leave for both primary and secondary career#GiveBackDays/Commitment to social impact – 3 extra days off to volunteer and give back to your local communityOngoing dedication to Diversity & Inclusion initiatives such as D&I Council  Global Mentorship ProgramAccess to free mental health supportFlexible working arrangementsThe average base salary pay range for this role is between $70 000-$90 000 USDMay be considered for a discretionary bonus More About UsWe're the first global platform combining SaaS with embedded payments  and tools to help businesses grow and succeed. We offer software solutions in fast-growing ‘everyday life’ verticals: Education  Fitness & Wellbeing  Field Services and Personal Services – and a global  cloud-based payments processing platform. Xplor Technologies serves over 106 000 customers that processed over $37 billion in payments  operating across 20 markets in 2023.Good to knowTo be considered for employment  you must be legally authorized to work in the location (country) you're applying for. Xplor does not sponsor visas  either at the time of hire or at any later time.We kindly ask you to apply through our careers portal or external job boards only. Please don't send your application via email.To learn more about us and our products  please visit www.xplortechnologies.com/us/careers.We also invite you to check out our Candidate FAQs for more information about our recruitment process www.xplortechnologies.com/us/recruitment-faqs.Xplor is proud to be an Equal Employment Opportunity employer. We're dedicated to attracting  retaining and developing our people regardless of gender identity  ethnicity  sexual orientation  disability  veteran status and age. Applications are encouraged from all sectors of the community.All Information will be kept confidential according to EEO guidelines.Xplor is committed to the full inclusion of all qualified individuals. In keeping with our commitment  Xplor will take the steps to assure that people with disabilities are provided reasonable accommodations. Accordingly  if reasonable accommodation is required to fully participate in the job application or interview process  to perform the essential functions of the position  and/or to receive all other benefits and privileges of employment  please contact us via talent@xplortechnologies.com.We are a 2024 Circle Back Initiative Employer – we commit to respond to every applicant.,Mid-Senior level,Full-time\n",
      "\n",
      "Worth AI  a dynamic player in the computer software industry  is seeking a skilled and motivated individual to join their team as a Data Engineer. Worth AI is committed to transforming decision-making using the power of AI while promoting equity  diversity  and inclusion. With core values centered around diversity of thought  teamwork  and adaptability  Worth AI is dedicated to making a positive impact in the business world.As a Data Engineer at Worth AI  you will play a crucial role in designing and implementing data pipelines  data integration solutions  and data infrastructure to support the company's AI initiatives. You will collaborate closely with data scientists  software engineers  and other stakeholders to ensure effective data management and accessibility. Your expertise in data processing  data modeling  and database optimization will be essential in delivering scalable and reliable data solutions.ResponsibilitiesDesign  build  and maintain large-scale data processing systems and architectures that support AI initiativesDevelop and implement data pipelines and ETL processes to ingest  transform  and load data from various sourcesDesign and optimize databases and data storage solutions for high performance and scalabilityCollaborate with cross-functional teams to understand data requirements and ensure data quality and integrityImplement data governance and data security measures to protect sensitive dataMonitor and troubleshoot data infrastructure and pipeline issues in a timely mannerStay up-to-date with the latest trends and technologies in data engineering and recommend improvements to enhance the company's data capabilitiesRequirementsProven experience as a Data Engineer or similar role  preferably in a software or technology-driven company with experience processing several to several hundreds of Gigabytes of data or moreIn-depth knowledge of data modeling  data warehousing  and database design principlesStrong programming skills in Python  SQL  and other relevant languagesExperience with relational and NoSQL databases  such as PostgreSQL  MySQL  MongoDBProficiency in data integration and ETL tools  such as Apache Kafka  Apache Airflow  or InformaticaFamiliarity with big data processing frameworks  such as Hadoop  Spark  or FlinkKnowledge of cloud platforms  such as AWS  Azure  or GCP  and experience with data storage and processing services in the cloudUnderstanding of data governance  data privacy  and data security best practicesStrong problem-solving and troubleshooting skills  with a focus on data quality and system performanceExcellent communication and collaboration skills to work effectively with cross-functional teamsPrior collaborative work with data scientists or machine learning professionals with respect to sourcing  processing and scaling both input and output dataComfortable going through documentation of third-party API's and identifying best procedures for integrating data from API's into broader ETL processes BenefitsHealth Care Plan (Medical  Dental & Vision)Retirement Plan (401k  IRA)Life InsuranceUnlimited Paid Time Off9 paid HolidaysFamily LeaveWork From HomeFree Food & Snacks (for those who are in Orlando  FL)Wellness Resources,Mid-Senior level,Full-time\n",
      "\n",
      "About KnowBe4KnowBe4  the provider of the world's largest security awareness training and simulated phishing platform  is used by tens of thousands of organizations around the globe. KnowBe4 enables organizations to manage the ongoing problem of social engineering by helping them train employees to make smarter security decisions  every day.Fortune has ranked us as a best place to work for women  for millennials  and in technology for four years in a row! We have been certified as a \"Great Place To Work\" in 8 countries  plus we've earned numerous other prestigious awards  including Glassdoor's Best Places To Work.Our team values radical transparency  extreme ownership  and continuous professional development in a welcoming workplace that encourages all employees to be themselves. Whether working remotely or in-person  we strive to make every day fun and engaging; from team lunches to trivia competitions to local outings  there is always something exciting happening at KnowBe4.As a Data Engineer at KnowBe4  you'll be pivotal in crafting and refining data pipelines essential for AI project development and internal operations. Your core responsibilities include designing  implementing  and maintaining scalable data infrastructure to facilitate streamlined data processing and analysis.This role presents a unique opportunity to shape KnowBe4's operational landscape with innovative solutions. We seek individuals passionate about harnessing AI and AWS technologies to drive efficiency and elevate user experiences.Moreover  you'll leverage cutting-edge AWS tools like Bedrock  Firehose  Lambda  and EventBridge. By integrating APIs from Salesforce  Netsuite  Zendesk  and other vital business applications  you'll collaborate on tailoring solutions to address our internal users' diverse needs. Join us in revolutionizing internal operations and contributing to a safer digital environment.ResponsibilitiesDevelop  enhance  and fine-tune data pipelines tailored for internal data amalgamation from diverse solutions  optimizing processing and analysis to prime the data for RAG development.Ensure reliability  scalability  and efficiency of data infrastructure components  including databases  data warehouses  and ETL processes  leveraging AWS technologies.Collaborate with data scientists and engineers to support machine learning model development and deployment.Implement best practices for data governance  security  and compliance on AWS.Stay updated on emerging technologies and trends in data engineering and AWS technologies  recommending new tools and techniques.Minimum QualificationsBachelor's or Master's degree in Computer Science  Engineering  or related field.Extensive experience in data engineering  including designing and implementing data pipelines and architectures on AWS.Proficiency in programming languages such as Python or Java and experience with database technologies such as SQL and NoSQL.Strong understanding of CI/CD and Git Ops workflows.Strong analytical and problem-solving skills  for focussing on delivering high-quality solutions.Excellent communication and collaboration skills  with the ability to work effectively in a cross-functional team environment.Proficiency in Python or Java programming languages for data pipeline development and automation.Strong understanding of data engineering concepts and best practices  with hands-on experience in designing and implementing data pipelines.Experience with AWS services such as Amazon S3  Kinesis  Glue  Redshift  DynamoDB  and Athena.Knowledge of database technologies such as SQL and NoSQL  with experience in data modeling and schema design.Familiarity with big data technologies such as Apache Hadoop  Spark  or Kafka.Experience with data visualization tools such as Tableau or Power BI.Familiarity with CI/CD and Git Ops workflows for version control and automated deployment.Strong problem-solving skills and ability to optimize data pipelines for performance  scalability  and reliability.Excellent communication and interpersonal skills  with the ability to effectively collaborate with cross-functional teams.The base pay for this position ranges from $110 000 - $120 000  which will vary depending on how well an applicant's skills and experience align with the job description listed above.We will accept applications until 7/16/24.Our Fantastic BenefitsWe offer company-wide monthly bonuses  employee referral bonuses  401k matching (US)  fully paid medical insurance (US)  open/generous paid time off (length varies by country)  parental leave (length varies by country)  adoption assistance  tuition reimbursement  certification reimbursement  certification completion bonuses  gym benefits  and a relaxed dress code - all in a modern  high-tech  and fun work environment. For more details about our benefits  visit www.knowbe4.com/careers/benefits.Note: An applicant assessment and background check may be part of your hiring procedure.Individuals seeking employment at KnowBe4 are considered without prejudice to race  color  religion  national origin  age  sex  marital status  ancestry  physical or mental disability  veteran status  gender identity  sexual orientation or any other characteristic protected under applicable federal  state  or local law. If you require reasonable accommodation in completing this application  interviewing  completing any pre-employment testing  or otherwise participating in the employee selection process  please visit www.knowbe4.com/careers/request-accommodation.No recruitment agencies  please.,Associate,Full-time\n",
      "\n",
      "CAI is on the hunt for a dedicated and proficient Data Engineer to enrich our technologyefforts. As a pivotal part of our data team  you will construct and maintain the backbone of our data platform  creating the channels through which data flows seamlessly into our system. This role requires a mix of technical prowess and a keen understanding of business needs  ensuring our data solutions are robust and aligned with our company's vision.Key ResponsibilitiesConstruct  manage  and optimize data pipelines for data ingestion  storage  and provisioning.Work closely with data architects to implement their designs and uphold data standards.Utilize modern data storage  processing tools  and modeling techniques to prepare data for analytical or operational uses.Ensure the integrity and availability of data throughout the data lifecycle.Monitor system performance  identifying bottlenecks and devising solutions to improve data reliability and quality.Collaborate with data scientists and business analysts to support data-driven decisions and machine learning initiatives.Develop and maintain scalable and reliable data infrastructure to meet business requirements.Lead the integration of new data management technologies and software engineering tools into existing structures.QualificationsBachelor’s or Master’s degree in Computer Science  Engineering  or a related technical discipline.At least 3 years of hands-on experience in a data engineering role.Strong command over SQL  Python  and other relevant data manipulation languages.Experience with data modeling  ETL development  and data warehousing solutions  especially with platforms like Snowflake.Demonstrated ability to work with large  complex data sets.Excellent problem-solving skills and attention to detail.Superior communication abilities that let you convey intricate concepts to a non-technical audience with clarity.Proven track record of working in cross-functional teams to deliver stellar project outcomes.Other RequirementsExcellent oral and written communication skills in English/Fluent in EnglishAble to travel domestically and internationally as requiredAble to work in the US without sponsorship now or any time in the futureAbout CAICAI is a 100% employee-owned company established in 1996 that has grown to more than 800 people worldwide. We provide commissioning  qualification  validation  start-up  project management and other consulting services associated with operational readiness to FDA regulated and other mission-critical industries.Meeting a Higher StandardOur approach is simple; we put the client’s interests first  we do not stop until it is right  and we will do whatever it takes to get there.As owners of CAI  we are committed to living our Foundational Principles  both professionally and personally:We act with integrity.We serve each other.We serve society.We work for our future.With employee ownership  one person’s success is everyone’s success; we work diligently to accomplish team goals. We place Team Before Self  demonstrate Respect for Others  and possess a Can-Do Attitude (our core values). That is how we have grown exponentially.BenefitsOur full-time positions offer competitive compensation and benefits which include up to 15% retirement contribution  24 days PTO and 5 sick days per year  health insurance at extremely low cost to employee  financial support for both internal and external professional education as well as 70% long term disability paid for by the company.$122 000 - $155 000 a yearAverage base salary range - not including benefits.We are an equal opportunity employer; we are proud to employ veterans and promote diversity and inclusion in our workplace. Diversity is a strength for our global company. We pledge that CAI will be operated in a way that is fair and equitable to all – our employees  our customers  and the broader society.This job description is not all inclusive and you may be asked to do other duties. CAI will also consider for employment qualified applicants with criminal histories in a manner consistent with the requirements of the Fair Chance Act (FCA) / Fair Chance Ordinance (FCO).,Entry level,Full-time\n",
      "\n",
      "There are 2 actors on a network  people and machines. Just as usernames and passwords are used by people to access machines  machine identities are used by machines to identify and access each other. Venafi is the inventor of the technology that manages and protects machine identities  the most important security initiative in our Global 5000 customers. We are Warriors!Are you passionate about making a positive impact and protecting the world from cybercriminals? If so  you may be a natural Venafi Warrior!How You’ll Be Protecting The WorldVenafi is looking for a Data Engineer who will report to the Sr. Director of Enterprise Analytics to support their Data as a Service mission. The Data Engineer is responsible for designing  and developing high-performance  resilient  automated data pipelines  and data transformations that feed our cloud-based Enterprise Data Platform. You will work with data analysts to design data integrations that meet organizational needs within our Snowflake data ecosystem. You are comfortable with BI work from the requirements phase through ETL  all the way through the presentation layer of BI. You will also implement and govern Data Management best practices and proactively recommend approaches and solutions. Strong problem-solving skills are needed with the ability to work across multiple projects at a time.The Ideal Venafi Warrior Will Be Armed WithExpert in programming languages like SQL  Python  Scala etc.Working experience with Snowflake - data modelling  ELT using Snowflake SQL  implementing complex stored Procedures and standard DWH and ETL conceptsExpert knowledge of Snowflake concepts like Streams  Tasks  Snowpipes  Zero copy clone  time travel  query profiling  RBAC controls  virtual warehouse sizing and experience using these featuresProven track record in designing complex scalable pipelines using Cloud supported ELT Tools.Take initiative; identify key requirements in dynamic environmentsAbility to communicate effectively and credibly with stakeholders and other team membersExperience implementing Data warehouse  Data lakes in the cloudAbility to create & implement data engineering best practices for the full software development life cycle  including coding standards  code reviews  source control management  documentation  build processes  automated testing  and operations.5+ years of experienceWhile you are busy protecting the world  we’ve got you covered!In addition to fostering a virtual first collaborative environment  Venafi offers a benefits package that is in the top 10%. Venafi pays 90% of the monthly premium for medical insurance and 100% of the monthly premium for dental  vision  life insurance  short and long-term disability  and accident insurance for both team members and their families. We offer an open time off policy and observe 12 holidays each year. We also offer a 401(k) with company matching  company HSA contribution  2x salary employer-paid life insurance  parental leave  pet insurance  fertility  adoption and surrogacy benefits!More About VenafiVenafi is the undisputed leader in Machine Identity Management. Why? Because we created the category and are light years ahead of anyone that would consider competing! Gartner has recognized Venafi as number one in our space and as it turns out  one is NOT the loneliest number!Venafi is the inventor of the technology that secures and protects machine identities. The Venafi platform provides visibility  intelligence  and automation for SSL/TLS  IoT  mobile  cloud native  Kubernetes  and SSH machine identity types. Many of the largest organizations in the world use Venafi.Billions of dollars have been spent protecting usernames and passwords and almost nothing managing machine identities—organizations are just now realizing that managing and protecting machine identities is as important as managing usernames and passwords. The bad guys know this and are using stolen or forged machine identities in their cyberattacks. In fact  Gartner says 50% of network attacks will use machine identities.Come help us protect the world!The anticipated pay range for this position is $98 000 to $115 000. This is a general estimate for informational purposes only. The actual salary offered will be determined based on the candidate’s relevant qualifications  experience  and skills. Upon review of the candidates and based on the objective factors listed above  this position may be filled at a higher or lower tier.,Mid-Senior level,Full-time\n",
      "\n",
      "Loopio’s Data Enablement Team works together on a mission to transform the RFP response process into a rapid and seamless experience. Our team works across all platform portfolio features and delivers innovative solutions where it matters the most for our customers.We are looking for an experienced Data Engineer to build and support the delivery of data pipelines  used for analytics both internally by Loopio’s teams  embedded within the Loopio platform for our customers. Our perfect candidate has deep technical skills and is comfortable working in an evolving technology infrastructure. This is a unique opportunity to join a growing team of creative and passionate individuals committed to solving real world problems. You will empower engineers  product  and data scientists with tools that enable and streamline data-driven decision making  analysis  and feature development.You will partner closely with ML Engineers  Architects and Data Scientists  Product Managers  and other business stakeholders to help us take Loopio’s data value to the next level.What You'll Be DoingBe responsible for building  evolving and scaling data platforms and ETL pipelines  with an eye towards growth of our business and reliability of our dataPromote data-driven decision making across the organization through data expertiseBuild advanced automation tooling for data orchestration  evaluation  testing  monitoring  administration  and data operationsIntegrate various data sources into our Datalake  including clickstream  relational  and unstructured dataDeveloping and maintaining a feature store for use in analytics & modelingPartner with data scientists to create predictive models to help drive insights and decisions  both in Loopio’s product and internal teams (RevOps  Marketing  CX)Work closely with stakeholders within and across teams to understand the data needs of the business and produce processes that enable a better product and support data-driven decision-makingBuild scalable data pipelines using Databricks  and AWS (Redshift  S3  RDS)  and other cloud technologies Build and support Loopio’s data warehouse (Redshift) and data lake (Databricks deltalake)Orchestrate pipelines using workflow frameworks / tooling What You'll Bring to the Team3+ years experience in a data engineering or a similar roleExperience in a high growth agile software development environmentExperience building and supporting large-scale systems in a production environmentStrong communication  collaboration  and analytical skillsAbility to clearly communicate technical roadmap  challenges  and mitigationDemonstrated ability to work with a high degree of ambiguity  and leadership within a team (mentorship  ownership  innovationStrong understanding of database concepts  modeling  SQL  query optimizationAbility to learn fast and translate data into actionable resultsExperience developing in Python and Pyspark Hands-on experience with the AWS services (RDS  S3  Redshift  Glue  Quicksight  Athena  ECS)Strong understanding of relational databases (RDS  MySQL) and NoSQLExperience with ETL & Data warehousing  building fact & dimensional data modelsExperience with data processing frameworks such as Spark / DatabricksExperience in developing Big Data solutions (migration  storage  processing)Experience with CI/CD tools (Jenkins) and pipeline orchestration tools (Databricks Jobs  Airflow)Experience working with data visualization and BI platforms (Quicksight  Tableau  Sisense  etc)Experience working with Clickstream data (Amplitude  Pendo  etc)Bonus QualificationsExperience with container orchestration (leveraging tools like Docker  ECS  Kubernetes)Experience working with BI PaaS / SaaS solutionsFamiliarity with microservice architectures Experience with Natural Language Processing techniquesExperience using deep learning frameworks such as TensorFlow / PytorchWhere You'll WorkLoopio is a remote-first workplace because we recognize the advantages of working flexibly. We have two Hub Regions  which means that employees live and work within a 300 KM radius of Toronto (within Ontario) or Vancouver (within British Columbia) and work within regular business hours in their timezone. Loopio’s office headquarters are located in Toronto’s vibrant Kensington Market. All Loopers have the option to work from home. Ontario Loopers have the option to work in the Toronto HQ and BC Loopers may work from our co-working office in Gastown Vancouver. It is whatever works best for you!You’ll collaborate with your teams virtually (we’re just a Zoom call away!) and have established core sync hours and focus time during the workday to enable us to work smarter togetherWhy You'll Love Working at LoopioYour manager supports your development by providing ongoing feedback and regular 1-on-1s You have tons of autonomy and responsibility: this role provides an opportunity to try new things and push creative boundariesYou’ll learn more than you thought was possible; our team is obsessed with personal and professional growth (every Looper receives a professional mastery allowance each year)You’ll be set up to work remotely with a MacBook laptop  a monthly phone and internet allowance  and a work-from-home budget to help get your home office all set up! Join us in regular company socials  AMA (Ask-Me-Anything)  and quarterly kick-off to celebrate the big wins and milestones as #oneteam!You’ll be joining a culture that has thoughtfully built out opportunities for connections in a remote first environmentWe have Employee Resource Groups  House Teams (curious? ask us about it!)  virtual yoga  cooking classes and many more moments for us to have fun and learn together! You’ll be a part of an award-winning workplace and one of Canada’s fastest growing companies with ample opportunity to make a big impact here!,Not Applicable,Full-time\n",
      "\n",
      "Data Engineer Position AvailableTitle: Data EngineerMinimum Qualifications:Thrive in a fast-paced  cutting-edge technology environment.Proven experience with data modeling and developing Enterprise Data Warehouse solutions  including OLTP  OLAP  Dimensions  Facts  and Data modeling.Experience in designing and implementing data pipelines for BI and Machine Learning solutions.Knowledge of data security and privacy best practices.Expertise in Azure Monitor  Load Balancer  Application Gateway  Azure Functions  and Azure Data Factory Integrations.At least 5 years of hands-on experience in Data Management leveraging Microsoft Azure Cloud  including:Data integration and ETL: Azure Data Factory  Power BI Dataflow  SSIS.Database Management: Azure SQL Database  Azure Synapse Analytics  Azure Data Lake Storage  MSSQL  Cosmos DB  Analysis Services.Compute: Azure Functions.Monitoring: Azure Monitor.Container orchestration: Kubernetes.Experience working and communicating cross-functionally in a team environment.Ability to commute to one of our office locations.Preferred Qualifications:Certifications in data engineering AI/ML technologies and Azure  such as Azure AI Engineer  Azure Data Scientist  or Azure Solutions Architect.Responsibilities:Transform structured  semi-structured  and unstructured data into actionable insights.Lead  design  develop  and deliver large-scale data systems  data processing  and data transformation projects.Design and develop scalable  high-performance data pipelines using Azure cloud platform technologies.Build  test  and debug software packages and pipelines required for optimal extraction  loading  and transformation (ELT) of data from various sources.Implement best practices for data management  security  and governance.Document data pipelines  data models  and reports.Summary: We are seeking a Data Engineer to support one of our clients in designing and developing large-scale data systems and high-performance data pipelines using Azure technologies. The ideal candidate thrives in a fast-paced environment and has a minimum of 5 years of experience in data management and integration  with expertise in Azure Data Factory  Azure SQL Database  Azure Synapse Analytics  and Kubernetes. Responsibilities include transforming structured and unstructured data into actionable insights  implementing data security best practices  and documenting data models and pipelines. Preferred candidates will have relevant Azure certifications and experience with data modeling  ETL processes  and BI solutions. Candidates must live within commuting distance to one of our office locations.MUST be a US Citizen. Unfortunately  sponsorship is not available at this moment in time.,Mid-Senior level,Full-time\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_post_number = job_post_number[:10]\n",
    "\n",
    "import re\n",
    "with open(\"job_info.csv\", \"r+\",encoding=\"utf-8\") as f:\n",
    "    for i in job_post_number:\n",
    "        url = f\"https://www.linkedin.com/jobs-guest/jobs/api/jobPosting/{i}\"\n",
    "\n",
    "        session = HTMLSession()\n",
    "        r = session.get(url)\n",
    "        node = HTMLParser(r.text)\n",
    "\n",
    "\n",
    "        discriptions = node.css(\".description__text\")\n",
    "        more_info = node.css(\".description__job-criteria-text--criteria\")\n",
    "\n",
    "        all_discriptions  = discriptions[0].text().strip()[:-168]\n",
    "        all_discriptions = all_discriptions.replace(\",\",\" \")\n",
    "        all_info = [info.text().strip() for info in more_info]\n",
    "        seniority_level = all_info[0]\n",
    "        job_time_kind = all_info[1]\n",
    "        Industries = all_info[3]\n",
    "        f.write(f\"{all_discriptions},{seniority_level},{job_time_kind}\\n\")\n",
    "        print(f\"{all_discriptions},{seniority_level},{job_time_kind}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discribe</th>\n",
       "      <th>SL</th>\n",
       "      <th>workType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>At Netflix  our mission is to entertain the wo...</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is a remote position. Junior Data Enginee...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a remote position.Junior Data Engineer...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Company DescriptionAt Xplor we help businesses...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Worth AI  a dynamic player in the computer sof...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>About KnowBe4KnowBe4  the provider of the worl...</td>\n",
       "      <td>Associate</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CAI is on the hunt for a dedicated and profici...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>There are 2 actors on a network  people and ma...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Loopio’s Data Enablement Team works together o...</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Engineer Position AvailableTitle: Data En...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I solutions. Candidates must live within commu...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>teammate pay regularly to ensure competitive ...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Genesis10 is seeking a Data Engineer for a con...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>Contract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Engineer Position AvailableTitle: Data En...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>About CalmCalm is on a mission to support ever...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Join our team as a Data Engineer  where you'll...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Job DescriptioniTalent digital is seeking a Se...</td>\n",
       "      <td>Mid-Senior level</td>\n",
       "      <td>Full-time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             discribe                SL  \\\n",
       "0   At Netflix  our mission is to entertain the wo...    Not Applicable   \n",
       "1   This is a remote position. Junior Data Enginee...  Mid-Senior level   \n",
       "2   This is a remote position.Junior Data Engineer...  Mid-Senior level   \n",
       "3   Company DescriptionAt Xplor we help businesses...  Mid-Senior level   \n",
       "4   Worth AI  a dynamic player in the computer sof...  Mid-Senior level   \n",
       "5   About KnowBe4KnowBe4  the provider of the worl...         Associate   \n",
       "6   CAI is on the hunt for a dedicated and profici...       Entry level   \n",
       "7   There are 2 actors on a network  people and ma...  Mid-Senior level   \n",
       "8   Loopio’s Data Enablement Team works together o...    Not Applicable   \n",
       "9   Data Engineer Position AvailableTitle: Data En...  Mid-Senior level   \n",
       "10  I solutions. Candidates must live within commu...  Mid-Senior level   \n",
       "11   teammate pay regularly to ensure competitive ...       Entry level   \n",
       "12  Genesis10 is seeking a Data Engineer for a con...       Entry level   \n",
       "13  Data Engineer Position AvailableTitle: Data En...  Mid-Senior level   \n",
       "14  About CalmCalm is on a mission to support ever...  Mid-Senior level   \n",
       "15  Join our team as a Data Engineer  where you'll...  Mid-Senior level   \n",
       "16  Job DescriptioniTalent digital is seeking a Se...  Mid-Senior level   \n",
       "\n",
       "     workType  \n",
       "0   Full-time  \n",
       "1   Full-time  \n",
       "2   Full-time  \n",
       "3   Full-time  \n",
       "4   Full-time  \n",
       "5   Full-time  \n",
       "6   Full-time  \n",
       "7   Full-time  \n",
       "8   Full-time  \n",
       "9   Full-time  \n",
       "10  Full-time  \n",
       "11  Full-time  \n",
       "12   Contract  \n",
       "13  Full-time  \n",
       "14  Full-time  \n",
       "15  Full-time  \n",
       "16  Full-time  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df2 = pd.read_csv(\"job_info.csv\",names=[\"discribe\",\"SL\",\"workType\"])\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
